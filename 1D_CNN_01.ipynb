{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning - *SS19 - 27.06.2019*\n",
    "# 1D-CNN Tutorial 01: Simple 1D-CNNs in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Introduction](#introduction)<br>\n",
    "- [Revision: Convolutional Neural Networks](#Convolutional_Neural_Networks)<br>\n",
    "- [1D CNN vs. 2D CNN](#1D_CNN_vs_2D_CNN)<br>\n",
    "    - [What are the differences between 1D and 2D CNNs?](#What_are_the_differences_between_1D_and_2D_CNNs)<br>\n",
    "- [Construction of a 1D CNN in Keras](#Construction_of_a_1D_CNN_in_Keras)<br>\n",
    "    - [How to construct a 1D CNN in Keras?](#How_to_construct_a_1D_CNN_in_Keras)<br>\n",
    "- [1D-CNN text classification](#1D_CNN_text_classification)<br>\n",
    "    - [The dataset](#The_dataset)<br>  \n",
    "    - [Prepare data](#Prepare_data)<br>\n",
    "    - [Build model](#Build_model)<br>\n",
    "    - [Evaluation data](#Evaluation_data)<br>\n",
    "    - [Plot data](#Plot_data)\n",
    "    - [Predictions](#predictions)\n",
    "    - [Compromise](#compromise)\n",
    "- [Summary](#summary)<br>\n",
    "- [References](#references)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction<a id=\"introduction\"></a>\n",
    "\n",
    "This tutorial is about 1D convolutional neural networks (1D CNNs or 1D ConvNets) for text classification in Keras. It gives a short introduction about these types of neural networks and shows the diffrences between an one dimension CNN and a two dimension CNNs, which where already known.  \n",
    "Then the tutorial shows how to develop an exemplary one dimensional CNN step-by-step. Afterwards there's an excercise where you have to tune a CNN yourself to get to know the parameters better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revision: Convolutional Neural Networks <a id=\"Convolutional_Neural_Networks\"></a>\n",
    "\n",
    "A convolutional neural network (CNN or ConvNet), as we have already learned, is an artificial neural network. CNNs are used in numerous modern artificial intelligence technologies, primarily in the machine processing of image or audio data. Basically, the structure of a classic convolutional neural network consists of one or more convolutional layers, followed by a pooling layer and a fully-connected layer. In principle, this unit can be repeated as often as desired. \n",
    "\n",
    "By learning and applying features (training), it is possible to recognize patterns and objects through the network. Higher layers use the data of lower layers, so that even more complex patterns can be recognized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D CNNs versus 2D CNNs<a id=\"1D_CNN_vs_2D_CNN\"></a>\n",
    "\n",
    "The first tutorial about CNNs ('Simple convolutional neural network for handdrawn digit recognition in Keras') focused on a two dimensional convolutional neural network, which is especially suitable for image recognition problems. One dimensional convolutional neural network, on the other hand, are more commonly used for natural language processing (NLP) or analysis of time sequences of sensor data. Other or more specific examples could be audio signals, gyroscope or accelerometer data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the differences between 1D and 2D CNNs?<a id=\"What_are_the_differences_between_1D_and_2D_CNNs\"></a>\n",
    "\n",
    "CNNs, whether 1D, 2D or 3D CNNs, share the same properties and approach. The biggest difference is the dimensionality of the input data and the way the filters, also known as convolution kernel or feature detector, used move across the data. Below is a sample visualization of the data processing of a 1D CNN compared to a 2D CNN. The illustration is an excellent opportunity to demonstrate the different processing methods using examples:  \n",
    "\n",
    "![1D CNN and 2D CNN - Examples](img/1Dcnn_vs_2Dcnn.png \"1D CNN and 2D CNN - Examples\")\n",
    "\n",
    "**Explanatory note:** In the graphic on the left we see an example for NLP (example for 1D CNN). The set consists of six parts, each represented by a vector. The feature detector always covers the complete word, where the height of the Detector determines how many components of a sentence are taken into account during training. In this example, the height is two and the feature detector would iterate five times over the data. \n",
    "On the right side we see the example of a 2D CNN based on computer vision. Each pixel of the image is defined by an x and a y position. In addition, each pixel also contains the three values for RGB. The feature detector in this case has a dimension of 2x2. As suggested in the graphic, the feature detector moves horizontally and vertically across the image. \n",
    "\n",
    "The above-mentioned examples of the use of 1D CNNs already show that they are very effective in extracting characteristics from a fixed-length segment of the entire data set. However, it should not be too important in the evaluation where the characteristics are located in the segment. \n",
    "\n",
    "Another difference between 2D and 1D CNNs is that 1D networks allow the use of larger filter sizes. This means that if a 1D CNN uses a size 7 filter, it has only seven feature vectors, whereas a 2D CNN with a filter size of 7 would have 49 feature vectors, making it a very broad selection. Also, with 1D CNNs, you can use larger convolution windows. A small example: In a 2D convolution layer that uses a 3x 3 convolution window, nine feature vectors (3x3=9) are used. With a 1D convolution layer, a window of size 3 contains only three feature vectors, which means you can afford a window size of 7 or 9 easily.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction of a 1D CNN in Keras<a id=\"Construction_of_a_1D_CNN_in_Keras\"></a>\n",
    "There are many standard CNN models that Keras provides. All models can be viewed in detail on the Keras website: https://keras.io/getting-started/sequential-model-guide/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to construct a 1D CNN in Keras?<a id=\"How_to_construct_a_1D_CNN_in_Keras\"></a>\n",
    "\n",
    "To understand the steps a 1D CNN goes through, we will look at a simplified example that provides an overview.\n",
    "\n",
    "![Contruction of a 1D CNN](img/aufbau_1d_cnn.png \"Contruction of a 1D CNN\")\n",
    "\n",
    "To make the graphic even more understandable, a few additions to the individual layers. Each input is a matrix defined by height and width. The \"height\" is the length of a data set that is fed into the network. It is also called the input height. The \"width\" or also called depth is the width of a data set that is fed into the network.\n",
    "\n",
    "Pooling is divided into average, mean and max pooling. Pooling layers have the advantage that they reduce the variance, increase the calculation performance, offer possibilities to create deeper networks, which in turn can solve more complex tasks and are a preventive measure against overfitting.\n",
    "Most often, though, 1D CNNs use max pooling. How the max pooling works is described in the figure. Average pooling works roughly as follows: It counts everything and then flows to the next layer, which means that all values are actually used for feature mapping and output - which is a very generalized calculation. If we don't need all inputs from the conv layer, we get a poor accuracy for the average pooling. However, it is well suited for object localization. Since mean pooling has proven to be less relevant and efficient, we won't go into that further.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D-CNN text classification<a id=\"1D_CNN_text_classification\"></a>\n",
    "\n",
    "The phyton code of a 1D CNN is almost analogous to that of a 2D CNN, meaning that most of the commands to create a CNN are identical or at least similar. In this example, a simple 1D CNN model is created, fed with data, and then trained. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset<a id=\"The_dataset\"></a>\n",
    "\n",
    "As our dataset we will use the IMDB dataset, which was already used in the machine learning exercise. Before you start, a little note: Run all code snipes to make sure the 1D CNN creation exercise works smoothly!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data<a id=\"Prepare_data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Conv1D, GlobalMaxPooling1D, Embedding\n",
    "from keras.datasets import imdb\n",
    "from keras.utils import plot_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Graphic output\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "test_data = x_test\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "#print(x_train[450])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IMDB data set consists of 25,000 pre-processed positive and negative film critiques. In pre-processing, each critic is encoded into a sequence of word indices. Same words are assigned to the same number (integer). \n",
    "\n",
    "**Example:** ? hello world how is it --> 1 2 3 4 5 6 || ? good question world lkz --> 1 7 8 3 0. \n",
    "\n",
    "Then the data set is re-indexed according to the number of contained words and their frequency. This means that the third value in the list is the third most common word in the list. As a convention, \"0\" does not stand for a specific word, but instead is used to encode any unknown word. \n",
    "This allows fast filter operations like: \"Consider only the 10,000 most common words\". [[5]](#r5)\n",
    "\n",
    "- 0 = 0: Stands for words that could not be translated. For example, if the word is not in the database and therefore not known\n",
    "- 1 = ?: Symbolizes the start of a critic\n",
    "\n",
    "Arguments:\n",
    "- **num_words:** integer or None. Top most frequent words to consider. Any less frequent word will appear as `oov_char` value in the sequence data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 800)\n",
      "x_test shape: (25000, 800)\n",
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(sequences=x_train, maxlen=800)\n",
    "x_test = sequence.pad_sequences(sequences=x_test, maxlen=800)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `pad_sequences` sets all sequences to the same length. `pad_sequences` converts the list of integers into a 2D numpy array (`num_samples`, `num_timesteps`). \n",
    "`num_timesteps` is either the specified maxlen argument or the length of the longest sequence in the list. All sequences that are shorter will be filled to the set length, all sequences that are longer than their set length will be trimmed. The length of the trimmed part is compared with the `num_timesteps` length and either filled or cut again. There is no rule of thumb for selecting the maximum length of the sequences, so you have to test this manually and adjust it to the results. \n",
    "What can be said, however, is that the smaller the sequences are selected, the less performance is required. But the recognition rate decreases. [[6]](#r6)\n",
    "\n",
    "Arguments:\n",
    "- **sequences:** List of lists, where each element is a sequence\n",
    "- **maxlen:** Int, maximum length of all sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model<a id=\"Build_model\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(input_dim=10000,\n",
    "                    output_dim=50,\n",
    "                    input_length=800))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efficient embedding converts positive integers (indices) into dense vectors of fixed size, meaning each word is converted into a vector of fixed length. Each word is always mapped to the same vector, so that information about the word is encoded in this vector. To use embedding layer, all words must be encoded using indexes. Since the data is already encoded, there is no need to index the data. \n",
    "\n",
    "In the next step, the numbers or words (indices) are converted into vectors. For example, the value [[2],[3],[4],[5],[6]] becomes the vector [[0.25, 0.1], [0.6, -0.2],[0.54, 0.3],[0.33, -0.55],[0.03, -0.09]]. \n",
    "\n",
    "The `output_dim` parameter can be used to decide how many dimensions are assigned to each index. \n",
    "For example, the vectors formed in the example have two dimensions. The generated vectors are now saved in the embedding layer and provided with an index. This index can be used to look up or edit the vector. The vectors of the individual words can be used to examine whether words are similar. When using an embedding layer, however, it should be noted that the embedding layer can only be used as the first layer (input layer) in a model. [[8](#r8)-[10](#r10)]\n",
    "\n",
    "![Embedding Example](img/embedding_example.png \"Embedding Example\")\n",
    "\n",
    "The argumnete used are:\n",
    "- **input_dim:** int > 0. Size of the vocabulary, i.e. maximum integer index + 1\n",
    "- **output_dim:** int >= 0. Dimension of the dense embedding\n",
    "- **input_length:** Length of input sequences, when it is constant. This argument is required if you are going to connect Flatten then Dense layers upstream (without it, the shape of the dense outputs cannot be computed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating an embedding layer, a dropout is generated. The dropout prevents the model from overfitting during the course. For this purpose, a fraction of values from the embedding layer is randomly set to 0. The dropout rate can be selected between 0.0 and 1.0. During each training phase, individual nodes are set to 0 with the specified probability and their edges are removed. This results in a new reduced network with different edge connections in each training phase.\n",
    "\n",
    "Following the training phase, the removed nodes are reinserted into the network with their original weight. For input nodes, you should make sure that the dropout rate is set low, for example 0.2. Otherwise information will be lost immediately before starting the training and will not be available during the entire training. For other nodes you can usually start with a dropout rate of 0.5. The dropout rate should nevertheless be adjusted according to the training results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv1D(filters=250,\n",
    "                 kernel_size=3,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a `Convolution1D` is added and the word group filters of size `filter_length` are learned. The convolutional layer consists of a layer of \"filters\". The filters each take up a subset of the input data that is applied over the entire input. During convolution, the input data is assigned to the filters via a linear matrix multiplication. At the end an activtation is made on all data.\n",
    "\n",
    "Here is an abstract model how the 1D Convolution works:\n",
    "<br>We call each row in the embedding layer and multiply each element in the block by the weight value and fill in the weighted sum in the output. Instead of a two-dimensional block, in a 1D convolution we use a one-dimensional block of the length of the kernel. This weighted sum is then distributed across all channels. It is also possible to create multiple convlutional layers in a row without having to use one between layers. [[[7]](#r7),[[8]](#r8),[[14]](#r14)]\n",
    "<br><table><tr>\n",
    "    <td>![Convolution process](img/conv_01.png \"Convolution process\")</td>\n",
    "    <td>![Convolution process](img/conv_02.png \"Convolution process\")</td>\n",
    "    <td>![Convolution process](img/conv_03.png \"Convolution process\")</td>\n",
    "</tr></table> \n",
    "\n",
    "The arguments:\n",
    "- **filters:** Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution)\n",
    "- **kernel_size:** An integer or tuple/list of a single integer, specifying the length of the 1D convolution window\n",
    "- **strides:** An integer or tuple/list of a single integer, specifying the stride length of the convolution. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1\n",
    "- **padding:** One of \"valid\", \"causal\" or \"same\" (case-insensitive). \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input. \"causal\" results in causal (dilated) convolutions, e.g. output[t] does not depend on input[t + 1:]. A zero padding is used such that the output has the same length as the original input. Useful when modeling temporal data where the model should not violate the temporal order\n",
    "- **activation:** The activation function. If you don't specify anything, no activation is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(GlobalMaxPooling1D())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pooling layer scans the output of the previous layer. This reduces the number of operations required for all subsequent layers without losing the valid information of the previous layer. [[11]](#r11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(250))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data changed by GlobalMaxPooling1D are then saved in a new dense layer. The advantage of a dense layer is that no information is lost with a dense layer, even if more or less layers are used than before. At this point, however, we use exactly as many dimensions as we have filters. This assigns each filter to one dimension. Then you execute an activation on the output. [[12]](#r12)\n",
    "\n",
    "![Dense Example](img/dense_example.png \"Dense Example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge the data on a single output layer (as a sequence) and execute a `sigmoid` on the output of the layer. More about activations: [[15]](#r15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])              \n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"626pt\" viewBox=\"0.00 0.00 462.00 626.00\" width=\"462pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 622)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-622 458,-622 458,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 1371404709000 -->\n",
       "<g class=\"node\" id=\"node1\"><title>1371404709000</title>\n",
       "<polygon fill=\"none\" points=\"65.5,-498.5 65.5,-544.5 388.5,-544.5 388.5,-498.5 65.5,-498.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"147\" y=\"-517.8\">embedding_1: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"228.5,-498.5 228.5,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256.5\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"228.5,-521.5 284.5,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256.5\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"284.5,-498.5 284.5,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"336.5\" y=\"-529.3\">(None, 800)</text>\n",
       "<polyline fill=\"none\" points=\"284.5,-521.5 388.5,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"336.5\" y=\"-506.3\">(None, 800, 50)</text>\n",
       "</g>\n",
       "<!-- 1371404709784 -->\n",
       "<g class=\"node\" id=\"node2\"><title>1371404709784</title>\n",
       "<polygon fill=\"none\" points=\"82,-415.5 82,-461.5 372,-461.5 372,-415.5 82,-415.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"147\" y=\"-434.8\">dropout_1: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"212,-415.5 212,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"240\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"212,-438.5 268,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"240\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"268,-415.5 268,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"320\" y=\"-446.3\">(None, 800, 50)</text>\n",
       "<polyline fill=\"none\" points=\"268,-438.5 372,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"320\" y=\"-423.3\">(None, 800, 50)</text>\n",
       "</g>\n",
       "<!-- 1371404709000&#45;&gt;1371404709784 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>1371404709000-&gt;1371404709784</title>\n",
       "<path d=\"M227,-498.366C227,-490.152 227,-480.658 227,-471.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"230.5,-471.607 227,-461.607 223.5,-471.607 230.5,-471.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1371863287904 -->\n",
       "<g class=\"node\" id=\"node3\"><title>1371863287904</title>\n",
       "<polygon fill=\"none\" points=\"80,-332.5 80,-378.5 374,-378.5 374,-332.5 80,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.5\" y=\"-351.8\">conv1d_1: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"207,-332.5 207,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"207,-355.5 263,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"263,-332.5 263,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"318.5\" y=\"-363.3\">(None, 800, 50)</text>\n",
       "<polyline fill=\"none\" points=\"263,-355.5 374,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"318.5\" y=\"-340.3\">(None, 798, 250)</text>\n",
       "</g>\n",
       "<!-- 1371404709784&#45;&gt;1371863287904 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>1371404709784-&gt;1371863287904</title>\n",
       "<path d=\"M227,-415.366C227,-407.152 227,-397.658 227,-388.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"230.5,-388.607 227,-378.607 223.5,-388.607 230.5,-388.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1371883034104 -->\n",
       "<g class=\"node\" id=\"node4\"><title>1371883034104</title>\n",
       "<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 454,-295.5 454,-249.5 0,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.5\" y=\"-268.8\">global_max_pooling1d_1: GlobalMaxPooling1D</text>\n",
       "<polyline fill=\"none\" points=\"287,-249.5 287,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"315\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"287,-272.5 343,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"315\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"343,-249.5 343,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"398.5\" y=\"-280.3\">(None, 798, 250)</text>\n",
       "<polyline fill=\"none\" points=\"343,-272.5 454,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"398.5\" y=\"-257.3\">(None, 250)</text>\n",
       "</g>\n",
       "<!-- 1371863287904&#45;&gt;1371883034104 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>1371863287904-&gt;1371883034104</title>\n",
       "<path d=\"M227,-332.366C227,-324.152 227,-314.658 227,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"230.5,-305.607 227,-295.607 223.5,-305.607 230.5,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1371803508072 -->\n",
       "<g class=\"node\" id=\"node5\"><title>1371803508072</title>\n",
       "<polygon fill=\"none\" points=\"105.5,-166.5 105.5,-212.5 348.5,-212.5 348.5,-166.5 105.5,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"157.5\" y=\"-185.8\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"209.5,-166.5 209.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"209.5,-189.5 265.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"265.5,-166.5 265.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-197.3\">(None, 250)</text>\n",
       "<polyline fill=\"none\" points=\"265.5,-189.5 348.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-174.3\">(None, 250)</text>\n",
       "</g>\n",
       "<!-- 1371883034104&#45;&gt;1371803508072 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>1371883034104-&gt;1371803508072</title>\n",
       "<path d=\"M227,-249.366C227,-241.152 227,-231.658 227,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"230.5,-222.607 227,-212.607 223.5,-222.607 230.5,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1371018495816 -->\n",
       "<g class=\"node\" id=\"node6\"><title>1371018495816</title>\n",
       "<polygon fill=\"none\" points=\"83.5,-83.5 83.5,-129.5 370.5,-129.5 370.5,-83.5 83.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"157.5\" y=\"-102.8\">activation_1: Activation</text>\n",
       "<polyline fill=\"none\" points=\"231.5,-83.5 231.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"259.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"231.5,-106.5 287.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"259.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"287.5,-83.5 287.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"329\" y=\"-114.3\">(None, 250)</text>\n",
       "<polyline fill=\"none\" points=\"287.5,-106.5 370.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"329\" y=\"-91.3\">(None, 250)</text>\n",
       "</g>\n",
       "<!-- 1371803508072&#45;&gt;1371018495816 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>1371803508072-&gt;1371018495816</title>\n",
       "<path d=\"M227,-166.366C227,-158.152 227,-148.658 227,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"230.5,-139.607 227,-129.607 223.5,-139.607 230.5,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1371826536576 -->\n",
       "<g class=\"node\" id=\"node7\"><title>1371826536576</title>\n",
       "<polygon fill=\"none\" points=\"105.5,-0.5 105.5,-46.5 348.5,-46.5 348.5,-0.5 105.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"157.5\" y=\"-19.8\">dense_2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"209.5,-0.5 209.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"209.5,-23.5 265.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"265.5,-0.5 265.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-31.3\">(None, 250)</text>\n",
       "<polyline fill=\"none\" points=\"265.5,-23.5 348.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-8.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 1371018495816&#45;&gt;1371826536576 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>1371018495816-&gt;1371826536576</title>\n",
       "<path d=\"M227,-83.3664C227,-75.1516 227,-65.6579 227,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"230.5,-56.6068 227,-46.6068 223.5,-56.6069 230.5,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1371404708720 -->\n",
       "<g class=\"node\" id=\"node8\"><title>1371404708720</title>\n",
       "<polygon fill=\"none\" points=\"175,-581.5 175,-617.5 279,-617.5 279,-581.5 175,-581.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"227\" y=\"-595.8\">1371404708720</text>\n",
       "</g>\n",
       "<!-- 1371404708720&#45;&gt;1371404709000 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>1371404708720-&gt;1371404709000</title>\n",
       "<path d=\"M227,-581.254C227,-573.363 227,-563.749 227,-554.602\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"230.5,-554.591 227,-544.591 223.5,-554.591 230.5,-554.591\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model,show_shapes = True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model is pre-configured for the training run. [[13]](#r13)<br>\n",
    "The argumnete used are:\n",
    "- **optimizer:** String (name of optimizer) or optimizer instance.\n",
    "- **loss:** String (name of objective function) or objective function. If the model has multiple outputs, you can use a different loss on each output by passing a dictionary or a list of losses. The loss value that will be minimized by the model will then be the sum of all individual losses.\n",
    "- **metrics:** List of metrics to be evaluated by the model during training and testing. Typically you will use metrics=['accuracy']. To specify different metrics for different outputs of a multi-output model, you could also pass a dictionary, such as metrics={'output_a': 'accuracy'}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 13s 503us/step - loss: 0.4422 - acc: 0.7743 - val_loss: 0.3430 - val_acc: 0.8511\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 10s 390us/step - loss: 0.2624 - acc: 0.8908 - val_loss: 0.2857 - val_acc: 0.8779\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 10s 392us/step - loss: 0.2055 - acc: 0.9202 - val_loss: 0.2823 - val_acc: 0.8813\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 10s 392us/step - loss: 0.1722 - acc: 0.9334 - val_loss: 0.2622 - val_acc: 0.8931\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 10s 390us/step - loss: 0.1429 - acc: 0.9467 - val_loss: 0.2895 - val_acc: 0.8886\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 10s 390us/step - loss: 0.1236 - acc: 0.9543 - val_loss: 0.2916 - val_acc: 0.8912\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 10s 392us/step - loss: 0.1117 - acc: 0.9565 - val_loss: 0.2987 - val_acc: 0.8846\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 10s 393us/step - loss: 0.1012 - acc: 0.9624 - val_loss: 0.3185 - val_acc: 0.8864\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 10s 393us/step - loss: 0.0942 - acc: 0.9642 - val_loss: 0.2951 - val_acc: 0.8904\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 10s 392us/step - loss: 0.0805 - acc: 0.9698 - val_loss: 0.3311 - val_acc: 0.8899\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=10,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trains the model on a data set for a specific number of iterations. [[13]](#r13)\n",
    "\n",
    "The arguments:\n",
    "- **x:** Numpy array of training data (if the model has a single input), or list of Numpy arrays (if the model has multiple inputs). If input layers in the model are named, you can also pass a dictionary mapping input names to Numpy arrays. x can be None (default) if feeding from framework-native tensors (e.g. TensorFlow data tensors)\n",
    "- **y:** Numpy array of target (label) data (if the model has a single output), or list of Numpy arrays (if the model has multiple outputs). If output layers in the model are named, you can also pass a dictionary mapping output names to Numpy arrays. y can be None (default) if feeding from framework-native tensors (e.g. TensorFlow data tensors)\n",
    "- **batch_size:** Integer or None. Number of samples per gradient update. If unspecified, `batch_size` will default to 32\n",
    "- **epochs:** Integer. Number of epochs to train the model. An epoch is an iteration over the entire x and y data provided. Note that in conjunction with initial_epoch, epochs is to be understood as \"final epoch\". The model is not trained for a number of iterations given by epochs, but merely until the epoch of index epochs is reached\n",
    "- **validation_data:** tuple (`x_val`,` y_val`) or tuple (`x_val`, `y_val`, `val_sample_weights`) on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data. `validation_data` will override `validation_split`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation data<a id=\"Evaluation_data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data<a id=\"Plot_data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_loss = history.history['val_loss']\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['acc']\n",
    "val_accuracy = history.history['val_acc']\n",
    "\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss', color='red')\n",
    "plt.plot(epochs,val_loss , 'b', label='Validation loss', color='green')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training acc', color='red')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation acc', color='green')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions<a id=\"predictions\"></a>\n",
    "\n",
    "Once you have trained your network, you would like to use it in a practical scenario. You can increase the likelihood of positive ratings\n",
    "with the predict method:  [[4]](#r4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 11s 422us/step - loss: 0.4405 - acc: 0.7794 - val_loss: 0.2893 - val_acc: 0.8790\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 10s 414us/step - loss: 0.2588 - acc: 0.8961 - val_loss: 0.2537 - val_acc: 0.8940\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 10s 398us/step - loss: 0.2070 - acc: 0.9180 - val_loss: 0.2723 - val_acc: 0.8862\n"
     ]
    }
   ],
   "source": [
    "model_prediction = Sequential()\n",
    "model_prediction.add(Embedding(10000, 50, input_length=800))\n",
    "model_prediction.add(Dropout(0.5))\n",
    "model_prediction.add(Conv1D(filters=250, kernel_size=3, padding='valid', activation='relu', strides=1))\n",
    "model_prediction.add(GlobalMaxPooling1D())\n",
    "model_prediction.add(Dense(250))\n",
    "model_prediction.add(Activation('relu'))\n",
    "model_prediction.add(Dense(1))\n",
    "model_prediction.add(Activation('sigmoid'))\n",
    "model_prediction.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])   \n",
    "#\n",
    "# training\n",
    "#\n",
    "history = model_prediction.fit(x_train, y_train, batch_size=32, epochs=3, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 2s 85us/step\n",
      "Accuracy on test set: [0.2722589012670517, 0.88616]\n",
      "Test loss: 0.2722589012670517\n",
      "Test accuracy: 0.88616\n"
     ]
    }
   ],
   "source": [
    "results = model_prediction.evaluate(x_test, y_test)\n",
    "print (\"Accuracy on test set:\" , results)\n",
    "print('Test loss:', results[0])\n",
    "print('Test accuracy:', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10029.,  1415.,   898.,   753.,   663.,   721.,   744.,  1018.,\n",
       "         1571.,  7188.]),\n",
       " array([6.7823334e-05, 1.0002697e-01, 1.9998612e-01, 2.9994527e-01,\n",
       "        3.9990440e-01, 4.9986356e-01, 5.9982270e-01, 6.9978184e-01,\n",
       "        7.9974103e-01, 8.9970016e-01, 9.9965930e-01], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model_prediction.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify a review of the test set that was predicted as positive (prediction score > 0.5) but was rated 0 (negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted score:  794\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_prediction.predict(x_test)\n",
    "prediction_is_positive = y_pred > 0.5\n",
    "label_is_negative = y_test.reshape((25000,1)) == 0\n",
    "\n",
    "incorrect_cases = np.where(np.logical_and( prediction_is_positive  , label_is_negative ))[0]\n",
    "#print (\"All incorrect cases: \",incorrect_cases[0:])\n",
    "print (\"Predicted score: \", len(incorrect_cases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compromise<a id=\"compromise\"></a>\n",
    "<br><table><tr>\n",
    "    <td>![Compromise CNN Plot](img/vergleich_cnn01_plot.png \"Compromise CNN Plot\")</td>\n",
    "    <td>![Compromise CNN Prediction](img/vergleich_cnn1_data.png \"[Compromise CNN Prediction\")</td>\n",
    "    </tr><tr>\n",
    "        <td>Compromise Plot</td>\n",
    "        <td>Compromise Prediction</td>\n",
    "</tr></table> \n",
    "\n",
    "The images `Compromise Plot` and `Compromise Prediction` are taken from the notebook `31_Neural_Networks_IMDB` [[4]](#r4) and should serve as validation of our model.\n",
    "If we compare the plots, we only see a slightly different distribution of the prediction values. The model from this notebook had more negative reviews than the model from notebook 31_Neural_Networks_IMDB. Which of the models makes the better prediction cannot be seen from the plot diagram. In both cases, the first 10 incorrectly marked reviews were checked. It is noticeable that our model makes a less \"wrong\" prediction than the model from the notebook 31_Neural_Networks_IMDB. However, since this value is not extremely different, it cannot be assumed that our model is actually a more suitable model. Both models could be improved by optimizations. In addition, both are simple examples. It should also be noted that the value moves back and forth within a certain range. This means that if the notebook is run through again, the model may perform worse, but also much better. The same is true for the other model. Therefore it is often the case in the AI area that several models are trained at the same time to find the best of all models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary<a id=\"summary\"></a>\n",
    "Let's recap what we have learned in this tutorial:\n",
    "\n",
    "- What is the idea behind 1D-CNN and how is it built?\n",
    "- How a 1D-CNN model is structured in Keras and how you can tune its parameters\n",
    "- How to train a model to fit a text dataset\n",
    "- How to visualize the training history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References<a id=\"references\"></a>\n",
    "\n",
    "### Code\n",
    "[1] https://github.com/keras-team/keras/blob/master/examples/imdb_cnn.py<a id=\"r1\"></a><br>\n",
    "[2] 13_Matplotlib (Deep Learning Exercise)<a id=\"r2\"></a><br>\n",
    "[3] 31_Neural_Networks_IMDB (Deep Learning Exercise)<a id=\"r3\"></a><br>\n",
    "[4] 41_CNNs_MNIST (Deep Learning bung)<a id=\"r4\"></a>\n",
    "\n",
    "### Explanations\n",
    "[5] https://keras.io/datasets/<a id=\"r5\"></a><br>\n",
    "[6] https://keras.io/preprocessing/sequence/<a id=\"r6\"></a><br>\n",
    "[7] https://keras.io/layers/convolutional/<a id=\"r7\"></a><br>\n",
    "[8] https://www.wandb.com/classes/intro/class-8<a id=\"r8\"></a><br>\n",
    "[9] https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526<a id=\"r9\"></a><br>\n",
    "[10] https://keras.io/layers/embeddings/<a id=\"r10\"></a><br>\n",
    "[11] https://keras.io/layers/pooling/<a id=\"r11\"></a><br>\n",
    "[12] https://keras.io/layers/core/<a id=\"r12\"></a><br>\n",
    "[13] https://keras.io/models/model/<a id=\"r13\"></a><br>\n",
    "\n",
    "### Other Rescources\n",
    "[14] https://www.youtube.com/watch?v=ST73HFC4Lpo<a id=\"r14\"></a><br>\n",
    "[15] https://medium.com/@abhigoku10/activation-functions-and-its-types-in-artifical-neural-network-14511f3080a8<a id=\"r15\"></a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## All-in-one solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Conv1D, GlobalMaxPooling1D, Embedding\n",
    "from keras.datasets import imdb\n",
    "from keras.utils import plot_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "#\n",
    "# Get data\n",
    "#\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "test_data = x_test\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "#print(x_train[450])\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(sequences=x_train, maxlen=800)\n",
    "x_test = sequence.pad_sequences(sequences=x_test, maxlen=800)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "#\n",
    "# prepeare model\n",
    "#\n",
    "model.add(Embedding(input_dim=10000, output_dim=100, input_length=800))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=250, kernel_size=3, padding='valid', activation='relu', strides=1))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(250))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])              \n",
    "#model.summary()\n",
    "SVG(model_to_dot(model,show_shapes = True).create(prog='dot', format='svg'))\n",
    "#\n",
    "# Training\n",
    "#\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))\n",
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "#\n",
    "# evaluation\n",
    "#\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print (\"Accuracy on test set:\" , results)\n",
    "print('Test loss:', results[0])\n",
    "print('Test accuracy:', results[1])\n",
    "#\n",
    "# Plot\n",
    "#\n",
    "val_loss = history.history['val_loss']\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['acc']\n",
    "val_accuracy = history.history['val_acc']\n",
    "\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss', color='red')\n",
    "plt.plot(epochs,val_loss , 'b', label='Validation loss', color='green')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training acc', color='red')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation acc', color='green')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#\n",
    "# PREDICTION\n",
    "#\n",
    "model_prediction = Sequential()\n",
    "model_prediction.add(Embedding(10000, 50, input_length=800))\n",
    "model_prediction.add(Dropout(0.5))\n",
    "model_prediction.add(Conv1D(filters=250, kernel_size=3, padding='valid', activation='relu', strides=1))\n",
    "model_prediction.add(GlobalMaxPooling1D())\n",
    "model_prediction.add(Dense(250))\n",
    "model_prediction.add(Activation('relu'))\n",
    "model_prediction.add(Dense(1))\n",
    "model_prediction.add(Activation('sigmoid'))\n",
    "model_prediction.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])   \n",
    "#\n",
    "# training\n",
    "#\n",
    "history = model_prediction.fit(x_train, y_train, batch_size=32, epochs=3, validation_data=(x_test, y_test))\n",
    "#\n",
    "# Evaluation\n",
    "#\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print (\"Accuracy on test set:\" , results)\n",
    "print('Test loss:', results[0])\n",
    "print('Test accuracy:', results[1])\n",
    "#\n",
    "# Plot\n",
    "#\n",
    "plt.hist(model_prediction.predict(x_test))\n",
    "#\n",
    "# Prediction\n",
    "#\n",
    "y_pred = model_prediction.predict(x_test)\n",
    "prediction_is_positive = y_pred > 0.5\n",
    "label_is_negative = y_test.reshape((25000,1)) == 0\n",
    "\n",
    "incorrect_cases = np.where(np.logical_and( prediction_is_positive  , label_is_negative ))[0]\n",
    "#print (\"All incorrect cases: \",incorrect_cases[0:])\n",
    "print (\"Predicted score: \", len(incorrect_cases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
